#!/usr/bin/env python3
"""
í•œêµ­ ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
í•œêµ­ ê¸ˆìœµìœ„ APIì—ì„œ KOSPI, KOSDAQ ë“± ì£¼ìš” ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘
"""

import requests
import json
import os
from datetime import datetime
import logging
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def fetch_index_data(date_str):
    """í•œêµ­ ì§€ìˆ˜ APIì—ì„œ ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘"""
    try:
        # API í‚¤ í™•ì¸
        api_key = os.getenv('KOREA_FINANCE_API_KEY')
        if not api_key:
            logger.error("âŒ í•œêµ­ ê¸ˆìœµìœ„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        # ì§€ìˆ˜ API URL
        url = "https://apis.data.go.kr/1160100/service/GetMarketIndexInfoService/getMarketIndexInfo"
        
        # ìˆ˜ì§‘í•  ì§€ìˆ˜ë“¤
        indices = ['KOSPI', 'KOSDAQ', 'KOSPI200']
        
        all_data = []
        
        for index_name in indices:
            params = {
                'serviceKey': api_key,
                'numOfRows': 1,
                'pageNo': 1,
                'resultType': 'xml',
                'basDt': date_str.replace('-', ''),
                'idxNm': index_name
            }
            
            try:
                response = requests.get(url, params=params, timeout=10)
                if response.status_code == 200:
                    # XML ì‘ë‹µ íŒŒì‹±
                    response_text = response.text
                    if 'NORMAL SERVICE' in response_text:
                        # XML ë°ì´í„° íŒŒì‹±
                        lines = response_text.strip().split('\n')
                        if len(lines) >= 2:
                            data_line = lines[1].strip()
                            fields = data_line.split()
                            if len(fields) >= 10:
                                index_data = {
                                    'idxNm': fields[3],  # ì§€ìˆ˜ëª…
                                    'clpr': fields[4],   # ì¢…ê°€
                                    'vs': fields[5],     # ì „ì¼ëŒ€ë¹„
                                    'fltRt': fields[6],  # ë“±ë½ë¥ 
                                    'oprc': fields[7],   # ì‹œê°€
                                    'hgpr': fields[8],   # ê³ ê°€
                                    'lwpr': fields[9],   # ì €ê°€
                                    'trqu': fields[10],  # ê±°ë˜ëŸ‰
                                    'basDt': fields[2]   # ê¸°ì¤€ì¼ì
                                }
                                all_data.append(index_data)
                                logger.info(f"âœ… {index_name} ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                            else:
                                logger.warning(f"âš ï¸ {index_name} ë°ì´í„° í˜•ì‹ ì˜¤ë¥˜")
                        else:
                            logger.warning(f"âš ï¸ {index_name} ë°ì´í„° ì—†ìŒ")
                    else:
                        logger.warning(f"âš ï¸ {index_name} ì„œë¹„ìŠ¤ ì˜¤ë¥˜")
                else:
                    logger.warning(f"âš ï¸ {index_name} ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
            except Exception as e:
                logger.warning(f"âš ï¸ {index_name} ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        
        if not all_data:
            logger.warning("âš ï¸ ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨. ë”ë¯¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return generate_dummy_index_data(date_str)
        
        logger.info(f"âœ… í•œêµ­ ì§€ìˆ˜ API ìš”ì²­ ì™„ë£Œ: {date_str} (ì´ {len(all_data)}ê°œ ì§€ìˆ˜)")
        return all_data
        
    except Exception as e:
        logger.error(f"âŒ í•œêµ­ ì§€ìˆ˜ API ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return generate_dummy_index_data(date_str)

def generate_dummy_index_data(date_str):
    """ë”ë¯¸ ì§€ìˆ˜ ë°ì´í„° ìƒì„±"""
    logger.info("ğŸ“Š ì§€ìˆ˜ ë”ë¯¸ ë°ì´í„° ìƒì„± ì¤‘...")
    
    dummy_data = [
        {
            'idxNm': 'KOSPI',
            'clpr': '2650.50',
            'vs': '25.30',
            'fltRt': '0.96',
            'oprc': '2625.20',
            'hgpr': '2660.80',
            'lwpr': '2620.10',
            'trqu': '850000000',
            'basDt': date_str.replace('-', '')
        },
        {
            'idxNm': 'KOSDAQ',
            'clpr': '850.20',
            'vs': '8.50',
            'fltRt': '1.01',
            'oprc': '841.70',
            'hgpr': '855.30',
            'lwpr': '840.50',
            'trqu': '450000000',
            'basDt': date_str.replace('-', '')
        },
        {
            'idxNm': 'KOSPI200',
            'clpr': '350.80',
            'vs': '3.20',
            'fltRt': '0.92',
            'oprc': '347.60',
            'hgpr': '352.40',
            'lwpr': '346.80',
            'trqu': '380000000',
            'basDt': date_str.replace('-', '')
        }
    ]
    
    logger.info(f"âœ… ì§€ìˆ˜ ë”ë¯¸ ë°ì´í„° ìƒì„± ì™„ë£Œ: {date_str} (ì´ {len(dummy_data)}ê°œ ì§€ìˆ˜)")
    return dummy_data

def parse_index_data(index_data_list):
    """ì§€ìˆ˜ ë°ì´í„° íŒŒì‹±"""
    index_data = {
        'timestamp': datetime.now().isoformat(),
        'kospi': {},
        'kosdaq': {},
        'kospi200': {},
        'summary': {}
    }
    
    try:
        if not index_data_list:
            logger.warning("âš ï¸ ìˆ˜ì§‘ëœ ì§€ìˆ˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return index_data
        
        for data in index_data_list:
            try:
                index_info = {
                    'name': data.get('idxNm', ''),
                    'close': float(data.get('clpr', 0)),
                    'change': float(data.get('vs', 0)),
                    'change_pct': float(data.get('fltRt', 0)),
                    'open': float(data.get('oprc', 0)),
                    'high': float(data.get('hgpr', 0)),
                    'low': float(data.get('lwpr', 0)),
                    'volume': int(data.get('trqu', 0)),
                    'date': data.get('basDt', '')
                }
                
                if data.get('idxNm') == 'KOSPI':
                    index_data['kospi'] = index_info
                elif data.get('idxNm') == 'KOSDAQ':
                    index_data['kosdaq'] = index_info
                elif data.get('idxNm') == 'KOSPI200':
                    index_data['kospi200'] = index_info
                    
            except (ValueError, TypeError) as e:
                logger.warning(f"âš ï¸ ì§€ìˆ˜ ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜: {e}")
                continue
        
        # ìš”ì•½ ì •ë³´ ìƒì„±
        if index_data['kospi'] and index_data['kosdaq']:
            index_data['summary'] = {
                'kospi_close': index_data['kospi']['close'],
                'kospi_change_pct': index_data['kospi']['change_pct'],
                'kosdaq_close': index_data['kosdaq']['close'],
                'kosdaq_change_pct': index_data['kosdaq']['change_pct'],
                'market_trend': 'ìƒìŠ¹' if index_data['kospi']['change_pct'] > 0 else 'í•˜ë½'
            }
        
        logger.info(f"âœ… ì§€ìˆ˜ ë°ì´í„° íŒŒì‹± ì™„ë£Œ: {len(index_data_list)}ê°œ ì§€ìˆ˜")
        
    except Exception as e:
        logger.error(f"âŒ ì§€ìˆ˜ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {e}")
    
    return index_data

def save_data(data, date_str):
    """ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    os.makedirs(f'data/{date_str}', exist_ok=True)
    filepath = f'data/{date_str}/kr_index.json'
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    logger.info(f"ğŸ’¾ ë°ì´í„° ì €ì¥: {filepath}")
    return filepath

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("ğŸ“ˆ í•œêµ­ ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    
    # ì˜¤ëŠ˜ ë‚ ì§œ
    today = datetime.now().strftime('%Y-%m-%d')
    
    # ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘
    index_data_list = fetch_index_data(today)
    
    # ë°ì´í„° íŒŒì‹±
    parsed_data = parse_index_data(index_data_list)
    
    # ë°ì´í„° ì €ì¥
    filepath = save_data(parsed_data, today)
    
    logger.info("âœ… í•œêµ­ ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
    return filepath

if __name__ == "__main__":
    main() 